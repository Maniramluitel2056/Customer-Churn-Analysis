{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1f9b88",
   "metadata": {},
   "source": [
    "# Customer Churn Analysis - Data Preprocessing\n",
    "\n",
    "This notebook handles the data preprocessing steps including loading the data, cleaning it, and encoding categorical variables.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192e252",
   "metadata": {},
   "source": [
    "### 1. Import Necessary Libraries and Configuration\n",
    "\n",
    "In this cell, we import all the necessary libraries and configurations needed for our data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8b9f8b02-a528-4f90-8abd-eaca9092cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: d:\\Customer-Churn-Analysis\\notebooks\\..\\config.json\n",
      "Raw data path (absolute): d:\\Customer-Churn-Analysis\\data/raw/Dataset (ATS)-1.csv\n",
      "Interim cleaned data path (absolute): d:\\Customer-Churn-Analysis\\data/interim/cleaned_dataset.csv\n",
      "Preprocessed data path (absolute): d:\\Customer-Churn-Analysis\\Data_Preparation/preprocessed_dataset/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(os.path.dirname(os.path.abspath('')), '..', 'config.json')\n",
    "print(f\"Config path: {config_path}\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "raw_data_path = os.path.join(project_root, config['raw_data_path'])\n",
    "interim_cleaned_data_path = os.path.join(project_root, config['interim_cleaned_data_path'])\n",
    "preprocessed_data_path = os.path.join(project_root, config['preprocessed_data_path'])\n",
    "\n",
    "# Print the absolute paths for verification\n",
    "print(f\"Raw data path (absolute): {raw_data_path}\")\n",
    "print(f\"Interim cleaned data path (absolute): {interim_cleaned_data_path}\")\n",
    "print(f\"Preprocessed data path (absolute): {preprocessed_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f16c3",
   "metadata": {},
   "source": [
    "### 2. Load Data\n",
    "\n",
    "This cell loads the raw data from the specified path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ad03d887-14c8-4deb-843e-6d8a837294e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns after loading dataset: ['gender', 'SeniorCitizen', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'MonthlyCharges', 'Churn']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>Contract</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>56.95</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>53.85</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>One year</td>\n",
       "      <td>42.30</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>70.70</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Dependents  tenure PhoneService MultipleLines  \\\n",
       "0  Female              0         No       1           No            No   \n",
       "1    Male              0         No      34          Yes            No   \n",
       "2    Male              0         No       2          Yes            No   \n",
       "3    Male              0         No      45           No            No   \n",
       "4  Female              0         No       2          Yes            No   \n",
       "\n",
       "  InternetService        Contract  MonthlyCharges Churn  \n",
       "0             DSL  Month-to-month           29.85    No  \n",
       "1             DSL        One year           56.95    No  \n",
       "2             DSL  Month-to-month           53.85   Yes  \n",
       "3             DSL        One year           42.30    No  \n",
       "4     Fiber optic  Month-to-month           70.70   Yes  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(raw_data_path)\n",
    "print(\"Initial columns after loading dataset:\", df.columns.tolist())\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27dc044",
   "metadata": {},
   "source": [
    "### 3. Clean Data\n",
    "\n",
    "In this cell, we clean the data by handling missing values and encoding categorical variables using OneHotEncoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cc301236-c6d4-4cd5-95dc-d338eb09457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values handled by dropping rows with missing values.\n",
      "Categorical columns identified: Index(['gender', 'Dependents', 'PhoneService', 'MultipleLines',\n",
      "       'InternetService', 'Contract', 'Churn'],\n",
      "      dtype='object')\n",
      "Categorical columns ['gender', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'Churn'] encoded.\n",
      "Columns after cleaning and encoding data: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female', 'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes', 'InternetService_DSL', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year', 'Churn_No', 'Churn_Yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>Churn_No</th>\n",
       "      <th>Churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
       "0              0       1           29.85            1.0          0.0   \n",
       "1              0      34           56.95            0.0          1.0   \n",
       "2              0       2           53.85            0.0          1.0   \n",
       "3              0      45           42.30            0.0          1.0   \n",
       "4              0       2           70.70            1.0          0.0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0            1.0             0.0              1.0               0.0   \n",
       "1            1.0             0.0              0.0               1.0   \n",
       "2            1.0             0.0              0.0               1.0   \n",
       "3            1.0             0.0              1.0               0.0   \n",
       "4            1.0             0.0              0.0               1.0   \n",
       "\n",
       "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
       "0               1.0                0.0                  1.0   \n",
       "1               1.0                0.0                  1.0   \n",
       "2               1.0                0.0                  1.0   \n",
       "3               1.0                0.0                  1.0   \n",
       "4               1.0                0.0                  0.0   \n",
       "\n",
       "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
       "0                          0.0                      1.0                0.0   \n",
       "1                          0.0                      0.0                1.0   \n",
       "2                          0.0                      1.0                0.0   \n",
       "3                          0.0                      0.0                1.0   \n",
       "4                          1.0                      1.0                0.0   \n",
       "\n",
       "   Contract_Two year  Churn_No  Churn_Yes  \n",
       "0                0.0       1.0        0.0  \n",
       "1                0.0       1.0        0.0  \n",
       "2                0.0       0.0        1.0  \n",
       "3                0.0       1.0        0.0  \n",
       "4                0.0       0.0        1.0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean the data by handling missing values and encoding categorical variables.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The data to clean.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Handle missing values by dropping rows with missing values\n",
    "        df = df.dropna()\n",
    "        print(\"Missing values handled by dropping rows with missing values.\")\n",
    "\n",
    "        # Identify and encode categorical variables\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "        print(f\"Categorical columns identified: {categorical_columns}\")\n",
    "        if len(categorical_columns) > 0:\n",
    "            # Initialize the OneHotEncoder\n",
    "            encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "            \n",
    "            # Fit and transform the categorical columns\n",
    "            encoded_data = pd.DataFrame(\n",
    "                encoder.fit_transform(df[categorical_columns]),\n",
    "                columns=encoder.get_feature_names_out(categorical_columns)\n",
    "            )\n",
    "            \n",
    "            # Drop the original categorical columns from the DataFrame\n",
    "            df = df.drop(columns=categorical_columns)\n",
    "            \n",
    "            # Concatenate the encoded data with the original DataFrame\n",
    "            df = pd.concat([df, encoded_data], axis=1)\n",
    "            print(f\"Categorical columns {list(categorical_columns)} encoded.\")\n",
    "        else:\n",
    "            print(\"No categorical columns found to encode.\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data cleaning: {e}\")\n",
    "\n",
    "# Clean the loaded data\n",
    "df_cleaned = clean_data(df)\n",
    "print(\"Columns after cleaning and encoding data:\", df_cleaned.columns.tolist())\n",
    "# Display the first few rows of the cleaned dataset\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4f61d-8c9d-4f52-afa8-588ac6637533",
   "metadata": {},
   "source": [
    "### 4. Save Cleaned Data\n",
    "\n",
    "This cell saves the cleaned data to the specified interim and preprocessed paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ef932a33-9060-41af-95e1-52aa0edc7244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to interim at d:\\Customer-Churn-Analysis\\data/interim/cleaned_dataset.csv\n",
      "Cleaned data saved to preprocessed at d:\\Customer-Churn-Analysis\\Data_Preparation/preprocessed_dataset/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(interim_cleaned_data_path, index=False)\n",
    "df_cleaned.to_csv(preprocessed_data_path, index=False)\n",
    "print(f\"Cleaned data saved to interim at {interim_cleaned_data_path}\")\n",
    "print(f\"Cleaned data saved to preprocessed at {preprocessed_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcea09e",
   "metadata": {},
   "source": [
    "## Task 2: Handle Missing Data and Encode Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d780221",
   "metadata": {},
   "source": [
    "### Handle Missing Data and Encode Categorical Variables\n",
    "In this step, we handle any missing data by imputing mean values for numeric columns and encode categorical variables using OneHotEncoder. This ensures that our dataset is clean and ready for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b0b63e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data handled by mean imputation.\n",
      "Categorical columns encoded: ['gender', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'Churn']\n",
      "Data after handling missing values and encoding:\n",
      "    SeniorCitizen  tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
      "0            0.0     1.0           29.85            1.0          0.0   \n",
      "1            0.0    34.0           56.95            0.0          1.0   \n",
      "2            0.0     2.0           53.85            0.0          1.0   \n",
      "3            0.0    45.0           42.30            0.0          1.0   \n",
      "4            0.0     2.0           70.70            1.0          0.0   \n",
      "\n",
      "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
      "0            1.0             0.0              1.0               0.0   \n",
      "1            1.0             0.0              0.0               1.0   \n",
      "2            1.0             0.0              0.0               1.0   \n",
      "3            1.0             0.0              1.0               0.0   \n",
      "4            1.0             0.0              0.0               1.0   \n",
      "\n",
      "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
      "0               1.0                0.0                  1.0   \n",
      "1               1.0                0.0                  1.0   \n",
      "2               1.0                0.0                  1.0   \n",
      "3               1.0                0.0                  1.0   \n",
      "4               1.0                0.0                  0.0   \n",
      "\n",
      "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
      "0                          0.0                      1.0                0.0   \n",
      "1                          0.0                      0.0                1.0   \n",
      "2                          0.0                      1.0                0.0   \n",
      "3                          0.0                      0.0                1.0   \n",
      "4                          1.0                      1.0                0.0   \n",
      "\n",
      "   Contract_Two year  Churn_No  Churn_Yes  \n",
      "0                0.0       1.0        0.0  \n",
      "1                0.0       1.0        0.0  \n",
      "2                0.0       0.0        1.0  \n",
      "3                0.0       1.0        0.0  \n",
      "4                0.0       0.0        1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iambh\\anaconda3\\envs\\churn_analysis\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>Churn_No</th>\n",
       "      <th>Churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
       "0            0.0     1.0           29.85            1.0          0.0   \n",
       "1            0.0    34.0           56.95            0.0          1.0   \n",
       "2            0.0     2.0           53.85            0.0          1.0   \n",
       "3            0.0    45.0           42.30            0.0          1.0   \n",
       "4            0.0     2.0           70.70            1.0          0.0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0            1.0             0.0              1.0               0.0   \n",
       "1            1.0             0.0              0.0               1.0   \n",
       "2            1.0             0.0              0.0               1.0   \n",
       "3            1.0             0.0              1.0               0.0   \n",
       "4            1.0             0.0              0.0               1.0   \n",
       "\n",
       "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
       "0               1.0                0.0                  1.0   \n",
       "1               1.0                0.0                  1.0   \n",
       "2               1.0                0.0                  1.0   \n",
       "3               1.0                0.0                  1.0   \n",
       "4               1.0                0.0                  0.0   \n",
       "\n",
       "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
       "0                          0.0                      1.0                0.0   \n",
       "1                          0.0                      0.0                1.0   \n",
       "2                          0.0                      1.0                0.0   \n",
       "3                          0.0                      0.0                1.0   \n",
       "4                          1.0                      1.0                0.0   \n",
       "\n",
       "   Contract_Two year  Churn_No  Churn_Yes  \n",
       "0                0.0       1.0        0.0  \n",
       "1                0.0       1.0        0.0  \n",
       "2                0.0       0.0        1.0  \n",
       "3                0.0       1.0        0.0  \n",
       "4                0.0       0.0        1.0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the utils directory to the system path\n",
    "utils_path = os.path.join(os.path.abspath(''), '..', 'utils')\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "# Now import the handle_missing_and_encode module\n",
    "from handle_missing_and_encode import handle_missing_and_encode\n",
    "\n",
    "# Handle missing data and encode categorical variables\n",
    "df_cleaned = handle_missing_and_encode(df)\n",
    "\n",
    "# Verify the cleaned data\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e3f9a",
   "metadata": {},
   "source": [
    "### Save Preprocessed Data\n",
    "After handling missing data and encoding categorical variables, we save the cleaned dataset to both interim and preprocessed paths. This allows us to have a checkpoint of our data before any further transformations or analyses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b05c5a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to interim at d:\\Customer-Churn-Analysis\\data/interim/cleaned_dataset.csv\n",
      "Cleaned data saved to preprocessed_dataset at d:\\Customer-Churn-Analysis\\Data_Preparation/preprocessed_dataset/cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to interim and preprocessed paths\n",
    "df_cleaned.to_csv(interim_cleaned_data_path, index=False)\n",
    "df_cleaned.to_csv(preprocessed_data_path, index=False)\n",
    "\n",
    "print(\"Cleaned data saved to interim at\", interim_cleaned_data_path)\n",
    "print(\"Cleaned data saved to preprocessed_dataset at\", preprocessed_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66143c79",
   "metadata": {},
   "source": [
    "## Task 3: Feature Scaling and Normalizing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a3f53",
   "metadata": {},
   "source": [
    "### Import Libraries and Configuration\n",
    "In this step, we import the necessary libraries and load the configuration file. We also convert the relative paths from the configuration file to absolute paths for easy access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "bd136903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: d:\\Customer-Churn-Analysis\\notebooks\\..\\config.json\n",
      "Raw data path (absolute): d:\\Customer-Churn-Analysis\\data/raw/Dataset (ATS)-1.csv\n",
      "Interim cleaned data path (absolute): d:\\Customer-Churn-Analysis\\data/interim/cleaned_dataset.csv\n",
      "Preprocessed data path (absolute): d:\\Customer-Churn-Analysis\\Data_Preparation/preprocessed_dataset/cleaned_dataset.csv\n",
      "Standard scaled data path (absolute): d:\\Customer-Churn-Analysis\\data_preparation/scaling_techniques/standard_scaled_dataset.csv\n",
      "Min-Max scaled data path (absolute): d:\\Customer-Churn-Analysis\\data_preparation/scaling_techniques/min_max_scaled_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(os.path.dirname(os.path.abspath('')), '..', 'config.json')\n",
    "print(f\"Config path: {config_path}\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "raw_data_path = os.path.join(project_root, config['raw_data_path'])\n",
    "interim_cleaned_data_path = os.path.join(project_root, config['interim_cleaned_data_path'])\n",
    "preprocessed_data_path = os.path.join(project_root, config['preprocessed_data_path'])\n",
    "standard_scaled_data_path = os.path.join(project_root, 'data_preparation/scaling_techniques/standard_scaled_dataset.csv')\n",
    "min_max_scaled_data_path = os.path.join(project_root, 'data_preparation/scaling_techniques/min_max_scaled_dataset.csv')\n",
    "\n",
    "print(f\"Raw data path (absolute): {raw_data_path}\")\n",
    "print(f\"Interim cleaned data path (absolute): {interim_cleaned_data_path}\")\n",
    "print(f\"Preprocessed data path (absolute): {preprocessed_data_path}\")\n",
    "print(f\"Standard scaled data path (absolute): {standard_scaled_data_path}\")\n",
    "print(f\"Min-Max scaled data path (absolute): {min_max_scaled_data_path}\")\n",
    "\n",
    "# Ensure the utils module can be found\n",
    "sys.path.append(os.path.join(project_root, 'utils'))\n",
    "\n",
    "# Import custom modules\n",
    "from data_loader import load_data\n",
    "from data_cleaner import clean_data\n",
    "from handle_missing_and_encode import handle_missing_and_encode\n",
    "from scaler import apply_standard_scaling, apply_min_max_scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab8f32",
   "metadata": {},
   "source": [
    "### Apply Standard Scaling\n",
    "In this step, we apply standard scaling to the numeric columns in the cleaned dataset. Standard scaling ensures that each feature has a mean of 0 and a standard deviation of 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "98d96dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns for scaling: Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female',\n",
      "       'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No',\n",
      "       'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes',\n",
      "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
      "       'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year',\n",
      "       'Churn_No', 'Churn_Yes'],\n",
      "      dtype='object')\n",
      "Standard scaling applied.\n",
      "Standard scaling applied.\n"
     ]
    }
   ],
   "source": [
    "# Apply standard scaling to numeric columns\n",
    "df_standard_scaled = apply_standard_scaling(df_cleaned)\n",
    "print(\"Standard scaling applied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917f9b3",
   "metadata": {},
   "source": [
    "### Apply Min-Max Scaling\n",
    "Here, we apply min-max scaling to the numeric columns in the cleaned dataset. Min-max scaling transforms the features by scaling each feature to a given range, typically between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a4fe5929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns for scaling: Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female',\n",
      "       'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No',\n",
      "       'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes',\n",
      "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
      "       'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year',\n",
      "       'Churn_No', 'Churn_Yes'],\n",
      "      dtype='object')\n",
      "Min-Max scaling applied.\n",
      "Min-Max scaling applied.\n"
     ]
    }
   ],
   "source": [
    "# Apply min-max scaling to numeric columns\n",
    "df_min_max_scaled = apply_min_max_scaling(df_cleaned)\n",
    "print(\"Min-Max scaling applied.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430bff8e",
   "metadata": {},
   "source": [
    "### Save Scaled Datasets and Verify\n",
    "In this final step, we save the scaled datasets to their respective paths and display the first few rows to verify the transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "944f77fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard scaled data saved at d:\\Customer-Churn-Analysis\\data_preparation/scaling_techniques/standard_scaled_dataset.csv\n",
      "Min-Max scaled data saved at d:\\Customer-Churn-Analysis\\data_preparation/scaling_techniques/min_max_scaled_dataset.csv\n",
      "First few rows of the standard scaled dataset:\n",
      "First few rows of the min-max scaled dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>Churn_No</th>\n",
       "      <th>Churn_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen    tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
       "0            0.0  0.013889        0.115423            1.0          0.0   \n",
       "1            0.0  0.472222        0.385075            0.0          1.0   \n",
       "2            0.0  0.027778        0.354229            0.0          1.0   \n",
       "3            0.0  0.625000        0.239303            0.0          1.0   \n",
       "4            0.0  0.027778        0.521891            1.0          0.0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0            1.0             0.0              1.0               0.0   \n",
       "1            1.0             0.0              0.0               1.0   \n",
       "2            1.0             0.0              0.0               1.0   \n",
       "3            1.0             0.0              1.0               0.0   \n",
       "4            1.0             0.0              0.0               1.0   \n",
       "\n",
       "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
       "0               1.0                0.0                  1.0   \n",
       "1               1.0                0.0                  1.0   \n",
       "2               1.0                0.0                  1.0   \n",
       "3               1.0                0.0                  1.0   \n",
       "4               1.0                0.0                  0.0   \n",
       "\n",
       "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
       "0                          0.0                      1.0                0.0   \n",
       "1                          0.0                      0.0                1.0   \n",
       "2                          0.0                      1.0                0.0   \n",
       "3                          0.0                      0.0                1.0   \n",
       "4                          1.0                      1.0                0.0   \n",
       "\n",
       "   Contract_Two year  Churn_No  Churn_Yes  \n",
       "0                0.0       1.0        0.0  \n",
       "1                0.0       1.0        0.0  \n",
       "2                0.0       0.0        1.0  \n",
       "3                0.0       1.0        0.0  \n",
       "4                0.0       0.0        1.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the scaled datasets\n",
    "df_standard_scaled.to_csv(standard_scaled_data_path, index=False)\n",
    "df_min_max_scaled.to_csv(min_max_scaled_data_path, index=False)\n",
    "print(f\"Standard scaled data saved at {standard_scaled_data_path}\")\n",
    "print(f\"Min-Max scaled data saved at {min_max_scaled_data_path}\")\n",
    "\n",
    "# Display the first few rows of the standard scaled dataset\n",
    "print(\"First few rows of the standard scaled dataset:\")\n",
    "df_standard_scaled.head()\n",
    "\n",
    "# Display the first few rows of the min-max scaled dataset\n",
    "print(\"First few rows of the min-max scaled dataset:\")\n",
    "df_min_max_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5cc83a",
   "metadata": {},
   "source": [
    "# Summary of Data Preprocessing\n",
    "## Overview\n",
    "In this notebook, we performed data preprocessing for the Customer Churn Analysis project. The preprocessing steps included data loading, cleaning, handling missing values, encoding categorical variables, and applying feature scaling and normalization.\n",
    "\n",
    "### Task 1: Load Data\n",
    "Objective: Load the raw dataset from the specified path.\n",
    "Process: We used pandas to read the CSV file and displayed the initial columns and first few rows to verify the data loading process.\n",
    "Result: Successfully loaded the raw dataset with the following columns: `['gender', 'SeniorCitizen', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'Contract', 'MonthlyCharges', 'Churn']`.\n",
    "\n",
    "### Task 2: Handle Missing Data and Encode Categorical Variables\n",
    "Objective: Handle any missing data and encode categorical variables for further analysis.\n",
    "Process:\n",
    "- Handle Missing Data: Used the SimpleImputer to impute mean values for numeric columns.\n",
    "- Encode Categorical Variables: Applied OneHotEncoder to convert categorical variables into one-hot encoded format.\n",
    "Result: The cleaned dataset was saved, and the columns were successfully encoded as one-hot vectors. The dataset now includes columns such as `['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female', 'gender_Male', 'Dependents_Yes', 'Dependents_No', 'PhoneService_Yes', 'PhoneService_No', 'MultipleLines_Yes', 'MultipleLines_No', 'InternetService_Fiber optic', 'InternetService_DSL', 'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year', 'Churn_No', 'Churn_Yes']`.\n",
    "\n",
    "### Task 3: Feature Scaling and Normalizing\n",
    "Objective: Apply standard scaling and min-max scaling to the numeric columns in the dataset.\n",
    "Process:\n",
    "- Standard Scaling: Used StandardScaler to transform the features such that they have a mean of 0 and a standard deviation of 1.\n",
    "- Min-Max Scaling: Applied MinMaxScaler to scale the features to a range between 0 and 1.\n",
    "Result: Both scaled datasets were saved to their respective paths, and the first few rows were displayed for verification.\n",
    "\n",
    "### Results Obtained\n",
    "- Initial Data Load: Successfully loaded the dataset with essential customer information.\n",
    "- Cleaned and Encoded Data: Handled missing values and encoded categorical variables into a suitable format for analysis.\n",
    "- Scaled Data: Applied standard scaling and min-max scaling to ensure the data is ready for modeling.\n",
    "\n",
    "### Next Steps\n",
    "1. Exploratory Data Analysis (EDA): Perform EDA to visualize and understand the relationships within the dataset.\n",
    "2. Feature Engineering: Create new features that might help improve the model performance.\n",
    "3. Modeling: Build and evaluate machine learning models to predict customer churn.\n",
    "\n",
    "By following this structured approach, we have ensured that the data is properly preprocessed and ready for further analysis and modeling. This summary captures the key steps and results, providing a clear overview of the preprocessing phase.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
