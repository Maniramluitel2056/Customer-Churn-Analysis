{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b59e31-2733-45b7-a1d9-2d3ebd15a66d",
   "metadata": {},
   "source": [
    "# K-means Clustering Analysis with Python\n",
    "## Overview\n",
    "This notebook guides you through the process of loading and preprocessing data, applying K-means clustering, and visualizing the results using Python. The analysis includes clustering customers based on their tenure and monthly charges using Min-Max scaled and Standard scaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f57b2c-4fc8-4dc6-a51a-3059a7709105",
   "metadata": {},
   "source": [
    "## Step 1: Importing Required Libraries\n",
    "First, import all the necessary libraries and modules that will be used for data processing, clustering, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51372f23-bfc3-4bc2-abe4-5cef2af0dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63568ab2-b699-4871-8d73-e0bc90183840",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Paths and Ensure Utility Modules are Accessible\n",
    "Here, we ensure that our custom utility modules can be accessed by setting up the correct paths. This step is important to make sure the script can locate and import necessary functions from other parts of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b573f53-8734-40c4-ae94-8decb834483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\notebooks\n",
      "Project root: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\n",
      "Utils path: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\utils\n",
      "Executing data_loader.py\n",
      "Executing handle_missing_and_encode.py\n"
     ]
    }
   ],
   "source": [
    "# Ensure the utils module can be found\n",
    "notebook_dir = os.path.dirname(os.path.abspath(''))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "utils_path = os.path.join(project_root, 'utils')\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Utils path: {utils_path}\")\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "try:\n",
    "    from data_loader import load_data\n",
    "    from data_cleaner import clean_data\n",
    "    from handle_missing_and_encode import handle_missing_and_encode\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing module: {e}\")\n",
    "    sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e625e5-8cce-494a-891a-7979c9ca0a13",
   "metadata": {},
   "source": [
    "## Step 3: Load Configuration and Set Up Paths\n",
    "In this step, we load configuration settings from `config.json` and convert relative paths to absolute paths to ensure that the correct data files are accessed during the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea75b065-407c-4a14-a361-cd8632c34c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config path: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\notebooks\\..\\config.json\n",
      "Raw data path (absolute): C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data/raw/Dataset (ATS)-1.csv\n",
      "Interim cleaned data path (absolute): C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data/interim/cleaned_dataset.csv\n",
      "Preprocessed data path (absolute): C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\Data_Preparation/preprocessed_dataset/cleaned_dataset.csv\n",
      "Standard scaled data path (absolute): C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data_preparation/scaling_techniques/standard_scaled_dataset.csv\n",
      "Min-Max scaled data path (absolute): C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data_preparation/scaling_techniques/min_max_scaled_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config_path = os.path.join(os.path.dirname(os.path.abspath('')), '..', 'config.json')\n",
    "print(f\"Config path: {config_path}\")\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "raw_data_path = os.path.join(project_root, config['raw_data_path'])\n",
    "interim_cleaned_data_path = os.path.join(project_root, config['interim_cleaned_data_path'])\n",
    "preprocessed_data_path = os.path.join(project_root, config['preprocessed_data_path'])\n",
    "standard_scaled_data_path = os.path.join(project_root, 'data_preparation/scaling_techniques/standard_scaled_dataset.csv')\n",
    "min_max_scaled_data_path = os.path.join(project_root, 'data_preparation/scaling_techniques/min_max_scaled_dataset.csv')\n",
    "\n",
    "print(f\"Raw data path (absolute): {raw_data_path}\")\n",
    "print(f\"Interim cleaned data path (absolute): {interim_cleaned_data_path}\")\n",
    "print(f\"Preprocessed data path (absolute): {preprocessed_data_path}\")\n",
    "print(f\"Standard scaled data path (absolute): {standard_scaled_data_path}\")\n",
    "print(f\"Min-Max scaled data path (absolute): {min_max_scaled_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adc7e7-721f-4fd9-90e4-6a91ccd6fe92",
   "metadata": {},
   "source": [
    "## Step 4: Load the Preprocessed Data\n",
    "Load the preprocessed datasets (both Min-Max scaled and Standard scaled) to prepare them for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc6a5c6-acc0-4e74-819f-87f539d494de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max scaled data loaded successfully from C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data_preparation/scaling_techniques/min_max_scaled_dataset.csv\n",
      "Standard scaled data loaded successfully from C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\data_preparation/scaling_techniques/standard_scaled_dataset.csv\n",
      "Standard Scaled Data:\n",
      "   SeniorCitizen    tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
      "0      -0.439916 -1.277445       -1.160323       1.009559    -1.009559   \n",
      "1      -0.439916  0.066327       -0.259629      -0.990532     0.990532   \n",
      "2      -0.439916 -1.236724       -0.362660      -0.990532     0.990532   \n",
      "3      -0.439916  0.514251       -0.746535      -0.990532     0.990532   \n",
      "4      -0.439916 -1.236724        0.197365       1.009559    -1.009559   \n",
      "\n",
      "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
      "0       0.654012       -0.654012         3.054010         -3.054010   \n",
      "1       0.654012       -0.654012        -0.327438          0.327438   \n",
      "2       0.654012       -0.654012        -0.327438          0.327438   \n",
      "3       0.654012       -0.654012         3.054010         -3.054010   \n",
      "4       0.654012       -0.654012        -0.327438          0.327438   \n",
      "\n",
      "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
      "0          0.854176          -0.854176             0.885660   \n",
      "1          0.854176          -0.854176             0.885660   \n",
      "2          0.854176          -0.854176             0.885660   \n",
      "3          0.854176          -0.854176             0.885660   \n",
      "4          0.854176          -0.854176            -1.129102   \n",
      "\n",
      "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
      "0                    -0.885660                 0.904184          -0.514249   \n",
      "1                    -0.885660                -1.105970           1.944582   \n",
      "2                    -0.885660                 0.904184          -0.514249   \n",
      "3                    -0.885660                -1.105970           1.944582   \n",
      "4                     1.129102                 0.904184          -0.514249   \n",
      "\n",
      "   Contract_Two year  Churn_No  Churn_Yes  \n",
      "0          -0.562975  0.601023  -0.601023  \n",
      "1          -0.562975  0.601023  -0.601023  \n",
      "2          -0.562975 -1.663829   1.663829  \n",
      "3          -0.562975  0.601023  -0.601023  \n",
      "4          -0.562975 -1.663829   1.663829  \n",
      "Min-Max Scaled Data:\n",
      "   SeniorCitizen    tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
      "0            0.0  0.013889        0.115423            1.0          0.0   \n",
      "1            0.0  0.472222        0.385075            0.0          1.0   \n",
      "2            0.0  0.027778        0.354229            0.0          1.0   \n",
      "3            0.0  0.625000        0.239303            0.0          1.0   \n",
      "4            0.0  0.027778        0.521891            1.0          0.0   \n",
      "\n",
      "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
      "0            1.0             0.0              1.0               0.0   \n",
      "1            1.0             0.0              0.0               1.0   \n",
      "2            1.0             0.0              0.0               1.0   \n",
      "3            1.0             0.0              1.0               0.0   \n",
      "4            1.0             0.0              0.0               1.0   \n",
      "\n",
      "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
      "0               1.0                0.0                  1.0   \n",
      "1               1.0                0.0                  1.0   \n",
      "2               1.0                0.0                  1.0   \n",
      "3               1.0                0.0                  1.0   \n",
      "4               1.0                0.0                  0.0   \n",
      "\n",
      "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
      "0                          0.0                      1.0                0.0   \n",
      "1                          0.0                      0.0                1.0   \n",
      "2                          0.0                      1.0                0.0   \n",
      "3                          0.0                      0.0                1.0   \n",
      "4                          1.0                      1.0                0.0   \n",
      "\n",
      "   Contract_Two year  Churn_No  Churn_Yes  \n",
      "0                0.0       1.0        0.0  \n",
      "1                0.0       1.0        0.0  \n",
      "2                0.0       0.0        1.0  \n",
      "3                0.0       1.0        0.0  \n",
      "4                0.0       0.0        1.0  \n"
     ]
    }
   ],
   "source": [
    "# Load the min-max scaled data\n",
    "df_min_max_scaled = pd.read_csv(min_max_scaled_data_path)\n",
    "print(f\"Min-Max scaled data loaded successfully from {min_max_scaled_data_path}\")\n",
    "df_standard_scaled = pd.read_csv(standard_scaled_data_path)\n",
    "print(f\"Standard scaled data loaded successfully from {standard_scaled_data_path}\")\n",
    "\n",
    "# Example of printing the first few rows to verify\n",
    "print(\"Standard Scaled Data:\")\n",
    "print(df_standard_scaled.head())\n",
    "\n",
    "print(\"Min-Max Scaled Data:\")\n",
    "print(df_min_max_scaled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9ab84-4a38-429c-9a13-a9f76d9c72f1",
   "metadata": {},
   "source": [
    "## Step 5: Apply K-means Clustering and Visualize Clusters\n",
    "Define a function to apply K-means clustering to the dataset and generate visualizations of the clusters. This function will also save the visualizations to a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17ce1b2-050f-4c86-a4e9-f2a56e4acb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kmeans_and_visualize(df, scaling_label, n_clusters):\n",
    "    # Define path for saving visualizations inside the function\n",
    "    visualizations_path = os.path.join(project_root, 'Clustering_Analysis', 'visualizations')\n",
    "    os.makedirs(visualizations_path, exist_ok=True)\n",
    "    \n",
    "    # Use only the 'tenure' and 'MonthlyCharges' columns for clustering\n",
    "    features = df[['tenure', 'MonthlyCharges']]\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(features)\n",
    "    \n",
    "    # Add cluster labels to the DataFrame\n",
    "    df['Cluster'] = kmeans.labels_\n",
    "    \n",
    "    # Visualize the clusters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=df, x='tenure', y='MonthlyCharges', hue='Cluster', palette='viridis')\n",
    "    plt.title(f'Customer Segments based on Tenure and Monthly Charges ({scaling_label} - Assumed 3 Clusters)')\n",
    "    plt.xlabel('Tenure')\n",
    "    plt.ylabel('Monthly Charges')\n",
    "    plt.legend(title='Cluster')\n",
    "    \n",
    "    # Save the visualization\n",
    "    visualization_filename = f'{scaling_label.lower().replace(\" \", \"_\")}_3_clusters_assumed.png'\n",
    "    visualization_filepath = os.path.join(visualizations_path, visualization_filename)\n",
    "    plt.savefig(visualization_filepath)\n",
    "    plt.close()\n",
    "    print(f'Saved cluster visualization: {visualization_filepath}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc467839-e234-4e28-ae6c-de24e5699008",
   "metadata": {},
   "source": [
    "## Step 6: Running K-means Clustering\n",
    "Apply K-means clustering with an assumed number of clusters (e.g., 3 clusters) to both the Min-Max scaled and Standard scaled datasets. Visualize and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "130f6e5a-09b7-41a5-abd3-fb15a32967c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cluster visualization: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\Clustering_Analysis\\visualizations\\min-max_scaled_3_clusters_assumed.png\n",
      "Saved cluster visualization: C:\\Users\\kusha\\OneDrive\\Documents\\Customer-Churn-Analysis-main\\Clustering_Analysis\\visualizations\\standard_scaled_3_clusters_assumed.png\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 3\n",
    "apply_kmeans_and_visualize(df_min_max_scaled, 'Min-Max Scaled', n_clusters)\n",
    "apply_kmeans_and_visualize(df_standard_scaled, 'Standard Scaled', n_clusters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac2ddc3-d65c-4317-91e7-3ae8f552bbf4",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This K-means clustering analysis segments customers based on their tenure and monthly charges. The clusters are visualized and saved, providing insights into different customer segments. The process includes importing necessary libraries, loading configuration files, preprocessing data, and visualizing the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018e10b-69e2-46dd-a90a-04316c7a9dad",
   "metadata": {},
   "source": [
    "# Next Steps:\n",
    "1. Optimal Clustering: Consider using methods like the Elbow Method or Silhouette Score to determine the optimal number of clustersCluster \n",
    "2. Interpretation: Examine the characteristics of each cluster for business insights.\n",
    "3. Advanced Analysis: Explore additional features and clustering techniques to refine the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaaa1d-952a-40fb-a2a9-0863f7e7c8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
