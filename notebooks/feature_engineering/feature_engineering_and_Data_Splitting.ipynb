{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Data Splitting\n",
    "\n",
    "In this notebook, we will perform data splitting and feature engineering for our customer churn analysis project. The steps include:\n",
    "1. Importing necessary libraries and setting up paths for loading the cleaned data.\n",
    "2. Creating new features to enhance model performance\n",
    "3. Splitting the data into training and testing sets\n",
    "4. Saving the processed data for further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Set Up Paths\n",
    "\n",
    "We start by importing necessary libraries and setting up paths to our data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim cleaned data path: d:\\Customer-Churn-Analysis\\data\\interim\\cleaned_dataset.csv\n",
      "Processed data path: d:\\Customer-Churn-Analysis\\data\\processed\\processed_dataset_with_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the base path using the current file's directory\n",
    "base_path = os.path.dirname(os.path.abspath(''))\n",
    "project_root = os.path.abspath(os.path.join(base_path, '..'))\n",
    "\n",
    "# Define paths to the data files\n",
    "interim_cleaned_data_path = os.path.join(project_root, 'data', 'interim', 'cleaned_dataset.csv')\n",
    "processed_data_path = os.path.join(project_root, 'data', 'processed', 'processed_dataset_with_features.csv')\n",
    "\n",
    "# Print the paths for verification\n",
    "print(f\"Interim cleaned data path: {interim_cleaned_data_path}\")\n",
    "print(f\"Processed data path: {processed_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Cleaned Data\n",
    "\n",
    "Next, we load the cleaned data from the specified path. This data has already been preprocessed to handle missing values and encode categorical variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from d:\\Customer-Churn-Analysis\\data\\interim\\cleaned_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): The path to the CSV file to be loaded.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The data loaded from the CSV file, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Load the cleaned data\n",
    "df_cleaned = load_data(interim_cleaned_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create New Features\n",
    "\n",
    "We will create new features to enhance the predictive power of our model. The features include `Charges_Per_Tenure`, `TotalCharges`, `Contract_Type`, and `Payment_Method`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>Churn_No</th>\n",
       "      <th>Churn_Yes</th>\n",
       "      <th>Charges_Per_Tenure</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.925000</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.627143</td>\n",
       "      <td>1936.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>107.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919565</td>\n",
       "      <td>1903.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.566667</td>\n",
       "      <td>141.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
       "0            0.0     1.0           29.85            1.0          0.0   \n",
       "1            0.0    34.0           56.95            0.0          1.0   \n",
       "2            0.0     2.0           53.85            0.0          1.0   \n",
       "3            0.0    45.0           42.30            0.0          1.0   \n",
       "4            0.0     2.0           70.70            1.0          0.0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0            1.0             0.0              1.0               0.0   \n",
       "1            1.0             0.0              0.0               1.0   \n",
       "2            1.0             0.0              0.0               1.0   \n",
       "3            1.0             0.0              1.0               0.0   \n",
       "4            1.0             0.0              0.0               1.0   \n",
       "\n",
       "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
       "0               1.0                0.0                  1.0   \n",
       "1               1.0                0.0                  1.0   \n",
       "2               1.0                0.0                  1.0   \n",
       "3               1.0                0.0                  1.0   \n",
       "4               1.0                0.0                  0.0   \n",
       "\n",
       "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
       "0                          0.0                      1.0                0.0   \n",
       "1                          0.0                      0.0                1.0   \n",
       "2                          0.0                      1.0                0.0   \n",
       "3                          0.0                      0.0                1.0   \n",
       "4                          1.0                      1.0                0.0   \n",
       "\n",
       "   Contract_Two year  Churn_No  Churn_Yes  Charges_Per_Tenure  TotalCharges  \n",
       "0                0.0       1.0        0.0           14.925000         29.85  \n",
       "1                0.0       1.0        0.0            1.627143       1936.30  \n",
       "2                0.0       0.0        1.0           17.950000        107.70  \n",
       "3                0.0       1.0        0.0            0.919565       1903.50  \n",
       "4                0.0       0.0        1.0           23.566667        141.40  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_features(df):\n",
    "    \"\"\"\n",
    "    Create new features for the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame for which new features will be created.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: The DataFrame with the newly created features.\n",
    "    \"\"\"\n",
    "    if 'tenure' in df.columns and 'MonthlyCharges' in df.columns:\n",
    "        df['Charges_Per_Tenure'] = df['MonthlyCharges'] / (df['tenure'] + 1)\n",
    "\n",
    "    if 'MonthlyCharges' in df.columns and 'tenure' in df.columns:\n",
    "        df['TotalCharges'] = df['MonthlyCharges'] * df['tenure']\n",
    "\n",
    "    contract_mapping = {\n",
    "        'Month-to-month': 0,\n",
    "        'One year': 1,\n",
    "        'Two year': 2\n",
    "    }\n",
    "    if 'Contract' in df.columns:\n",
    "        df['Contract_Type'] = df['Contract'].map(contract_mapping)\n",
    "\n",
    "    payment_mapping = {\n",
    "        'Electronic check': 0,\n",
    "        'Mailed check': 1,\n",
    "        'Bank transfer (automatic)': 2,\n",
    "        'Credit card (automatic)': 3\n",
    "    }\n",
    "    if 'PaymentMethod' in df.columns:\n",
    "        df['Payment_Method'] = df['PaymentMethod'].map(payment_mapping)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create new features for the cleaned data\n",
    "df_cleaned = create_new_features(df_cleaned)\n",
    "\n",
    "# Display the first few rows of the dataset with new features\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the Processed Dataset\n",
    "\n",
    "Finally, we save the dataset with the newly created features to the specified path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with new features saved to d:\\Customer-Churn-Analysis\\data\\processed\\processed_dataset_with_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset with new features\n",
    "df_cleaned.to_csv(processed_data_path, index=False)\n",
    "print(f\"Dataset with new features saved to {processed_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Data Splitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Configuration\n",
    "\n",
    "This cell imports the necessary libraries and loads the configuration file from the main directory. It finds the project root directory by searching for the `config.json` file and sets the file paths using the configuration settings. The absolute paths are printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: d:\\Customer-Churn-Analysis\n",
      "Config path: d:\\Customer-Churn-Analysis\\config.json\n",
      "Processed data path: d:\\Customer-Churn-Analysis\\data/processed/processed_dataset_with_features.csv\n",
      "Train path: d:\\Customer-Churn-Analysis\\data\\train\\train_dataset.csv\n",
      "Test path: d:\\Customer-Churn-Analysis\\data\\test\\test_dataset.csv\n",
      "Train path for Data Preparation: d:\\Customer-Churn-Analysis\\Data_Preparation\\training_sets\\train_dataset.csv\n",
      "Test path for Data Preparation: d:\\Customer-Churn-Analysis\\Data_Preparation\\testing_sets\\test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to find the project root directory by looking for config.json\n",
    "def find_project_root(filename='config.json'):\n",
    "    current_dir = os.getcwd()\n",
    "    while True:\n",
    "        if filename in os.listdir(current_dir):\n",
    "            return current_dir\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if parent_dir == current_dir:\n",
    "            raise FileNotFoundError(f\"{filename} not found in any parent directories.\")\n",
    "        current_dir = parent_dir\n",
    "\n",
    "# Find the project root directory\n",
    "root_dir = find_project_root()\n",
    "print(\"Project root directory:\", root_dir)\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(root_dir, 'config.json')\n",
    "print(\"Config path:\", config_path)\n",
    "\n",
    "# Ensure the config file exists\n",
    "if not os.path.exists(config_path):\n",
    "    raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Set file paths using the configuration settings\n",
    "processed_data_path = os.path.join(root_dir, config['processed_data_path'])\n",
    "train_path = os.path.join(root_dir, 'data', 'train', 'train_dataset.csv')\n",
    "test_path = os.path.join(root_dir, 'data', 'test', 'test_dataset.csv')\n",
    "train_path_prep = os.path.join(root_dir, 'Data_Preparation', 'training_sets', 'train_dataset.csv')\n",
    "test_path_prep = os.path.join(root_dir, 'Data_Preparation', 'testing_sets', 'test_dataset.csv')\n",
    "\n",
    "# Print the absolute paths for verification\n",
    "print(f\"Processed data path: {processed_data_path}\")\n",
    "print(f\"Train path: {train_path}\")\n",
    "print(f\"Test path: {test_path}\")\n",
    "print(f\"Train path for Data Preparation: {train_path_prep}\")\n",
    "print(f\"Test path for Data Preparation: {test_path_prep}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "This cell defines a function to load data from a specified CSV file path and prints a confirmation message upon successful loading. The processed dataset with new features is then loaded, and the first few rows of the dataset are displayed for verification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from d:\\Customer-Churn-Analysis\\data/processed/processed_dataset_with_features.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Dependents_No</th>\n",
       "      <th>Dependents_Yes</th>\n",
       "      <th>PhoneService_No</th>\n",
       "      <th>PhoneService_Yes</th>\n",
       "      <th>MultipleLines_No</th>\n",
       "      <th>MultipleLines_Yes</th>\n",
       "      <th>InternetService_DSL</th>\n",
       "      <th>InternetService_Fiber optic</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>Churn_No</th>\n",
       "      <th>Churn_Yes</th>\n",
       "      <th>Charges_Per_Tenure</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.925000</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>56.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.627143</td>\n",
       "      <td>1936.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>107.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919565</td>\n",
       "      <td>1903.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.566667</td>\n",
       "      <td>141.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  gender_Female  gender_Male  \\\n",
       "0            0.0     1.0           29.85            1.0          0.0   \n",
       "1            0.0    34.0           56.95            0.0          1.0   \n",
       "2            0.0     2.0           53.85            0.0          1.0   \n",
       "3            0.0    45.0           42.30            0.0          1.0   \n",
       "4            0.0     2.0           70.70            1.0          0.0   \n",
       "\n",
       "   Dependents_No  Dependents_Yes  PhoneService_No  PhoneService_Yes  \\\n",
       "0            1.0             0.0              1.0               0.0   \n",
       "1            1.0             0.0              0.0               1.0   \n",
       "2            1.0             0.0              0.0               1.0   \n",
       "3            1.0             0.0              1.0               0.0   \n",
       "4            1.0             0.0              0.0               1.0   \n",
       "\n",
       "   MultipleLines_No  MultipleLines_Yes  InternetService_DSL  \\\n",
       "0               1.0                0.0                  1.0   \n",
       "1               1.0                0.0                  1.0   \n",
       "2               1.0                0.0                  1.0   \n",
       "3               1.0                0.0                  1.0   \n",
       "4               1.0                0.0                  0.0   \n",
       "\n",
       "   InternetService_Fiber optic  Contract_Month-to-month  Contract_One year  \\\n",
       "0                          0.0                      1.0                0.0   \n",
       "1                          0.0                      0.0                1.0   \n",
       "2                          0.0                      1.0                0.0   \n",
       "3                          0.0                      0.0                1.0   \n",
       "4                          1.0                      1.0                0.0   \n",
       "\n",
       "   Contract_Two year  Churn_No  Churn_Yes  Charges_Per_Tenure  TotalCharges  \n",
       "0                0.0       1.0        0.0           14.925000         29.85  \n",
       "1                0.0       1.0        0.0            1.627143       1936.30  \n",
       "2                0.0       0.0        1.0           17.950000        107.70  \n",
       "3                0.0       1.0        0.0            0.919565       1903.50  \n",
       "4                0.0       0.0        1.0           23.566667        141.40  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed dataset with new features\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "df = load_data(processed_data_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Data\n",
    "\n",
    "This cell defines a function to split the dataset into training and testing sets using a specified test size and random state for reproducibility. The dataset is split into training and testing sets, and the sizes of these sets are printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training (size=5634) and testing (size=1409) sets.\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "def split_data(df, test_size=0.2, random_state=42):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    print(f\"Data split into training (size={len(train_df)}) and testing (size={len(test_df)}) sets.\")\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_data(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Split Data \n",
    "\n",
    "This cell saves the training and testing datasets to the specified paths in the main data directory and the Data Preparation directory. The paths are printed for verification, ensuring that the datasets are saved correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing datasets saved to d:\\Customer-Churn-Analysis\\data\\train\\train_dataset.csv and d:\\Customer-Churn-Analysis\\data\\test\\test_dataset.csv\n",
      "Training and testing datasets also saved to d:\\Customer-Churn-Analysis\\Data_Preparation\\training_sets\\train_dataset.csv and d:\\Customer-Churn-Analysis\\Data_Preparation\\testing_sets\\test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the training and testing datasets to the specified paths\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "train_df.to_csv(train_path_prep, index=False)\n",
    "test_df.to_csv(test_path_prep, index=False)\n",
    "print(f\"Training and testing datasets saved to {train_path} and {test_path}\")\n",
    "print(f\"Training and testing datasets also saved to {train_path_prep} and {test_path_prep}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Summary\n",
    "In this notebook, we have successfully performed feature engineering and data splitting on our dataset. Below is a summary of the tasks accomplished and the results obtained:\n",
    "\n",
    "## Task 1: Feature Engineering\n",
    "\n",
    "### Import Libraries and Set Up Paths\n",
    "\n",
    "- Imported necessary libraries and configuration settings.\n",
    "- Set up paths for loading and saving datasets.\n",
    "\n",
    "### Load Data\n",
    "\n",
    "- Loaded the raw dataset from the specified path.\n",
    "- Verified the initial structure and columns of the dataset.\n",
    "\n",
    "### Create New Features\n",
    "\n",
    "- Created new features to enhance the dataset, such as Charges_Per_Tenure and TotalCharges.\n",
    "- Encoded contract types and payment methods into numerical values for better analysis and modeling.\n",
    "\n",
    "### Save Processed Data\n",
    "\n",
    "- Saved the dataset with newly created features to a specified path for further analysis and modeling.\n",
    "\n",
    "## Task 2: Data Splitting\n",
    "\n",
    "### Import Libraries and Configuration\n",
    "\n",
    "- Imported necessary libraries and configuration settings.\n",
    "- Set up paths for loading the processed dataset and saving the split datasets.\n",
    "\n",
    "### Load Processed Data\n",
    "\n",
    "- Loaded the processed dataset with new features.\n",
    "- Verified the structure and columns of the loaded dataset.\n",
    "\n",
    "### Split Data\n",
    "\n",
    "- Split the dataset into training and testing sets using an 80-20 split.\n",
    "- Ensured the split datasets have the appropriate sizes.\n",
    "\n",
    "### Save Split Data\n",
    "\n",
    "- Saved the training and testing datasets to specified paths in both the main data directory and the Data Preparation directory.\n",
    "\n",
    "## Results Obtained\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "- The dataset now includes additional features that provide more insights and improve the model's ability to learn from the data.\n",
    "- The dataset is encoded and transformed, ready for further analysis and model training.\n",
    "\n",
    "### Data Splitting\n",
    "\n",
    "- The dataset is successfully split into training and testing sets, ensuring that we have separate data for model training and evaluation.\n",
    "- The split datasets are saved in designated directories, making them easily accessible for the next steps in the analysis.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Model Training: Use the training dataset to train various machine learning models.\n",
    "2. Model Evaluation: Use the testing dataset to evaluate the performance of the trained models and fine-tune them as needed.\n",
    "3. Exploratory Data Analysis (EDA): Perform detailed EDA on the training dataset to gain more insights and identify potential improvements for feature engineering.\n",
    "4. Model Selection and Deployment: Select the best-performing model based on evaluation metrics and prepare it for deployment.\n",
    "\n",
    "This concludes the feature engineering and data splitting tasks, setting a solid foundation for the subsequent stages in our data analysis and machine learning pipeline.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
