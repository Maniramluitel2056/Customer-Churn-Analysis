{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting and Feature Engineering\n",
    "\n",
    "In this notebook, we will perform data splitting and feature engineering for our customer churn analysis project. The steps include:\n",
    "1. Importing necessary libraries and setting up paths for loading the cleaned data.\n",
    "2. Creating new features to enhance model performance\n",
    "3. Splitting the data into training and testing sets\n",
    "4. Saving the processed data for further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing necessary libraries and setting up paths for loading the cleaned data.\n",
    "\n",
    "In this section, we will import the necessary libraries and set up paths for our project. We will also define a function to find the project root directory by looking for a config.json file. The configuration file will be used to set various file paths required for our data processing tasks.\n",
    "\n",
    "**Steps**:\n",
    "1. Import Libraries: We import essential libraries such as pandas, os, json, and scikit-learn modules for data preprocessing and model training.\n",
    "2. Find Project Root Directory: We define a function find_project_root to locate the project's root directory by searching for config.json file.\n",
    "3. Load Configuration: We load the configuration settings from the config.json file to set up file paths for raw data, cleaned data, preprocessed data, and other necessary paths.\n",
    "4. Load Cleaned Data: We load the cleaned dataset from the specified path for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root directory: d:\\Customer-Churn-Analysis\n",
      "Config path: d:\\Customer-Churn-Analysis\\config.json\n",
      "Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female',\n",
      "       'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No',\n",
      "       'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes',\n",
      "       'InternetService_DSL', 'InternetService_Fiber optic',\n",
      "       'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year',\n",
      "       'Churn_No', 'Churn_Yes', 'Charges_Per_Tenure', 'TotalCharges'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Function to find the project root directory by looking for config.json\n",
    "def find_project_root(filename='config.json'):\n",
    "    \"\"\"\n",
    "    Find the project root directory by looking for the specified filename.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): The filename to search for (default is 'config.json').\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the project root directory.\n",
    "    \"\"\"\n",
    "    current_dir = os.getcwd()\n",
    "    while True:\n",
    "        if filename in os.listdir(current_dir):\n",
    "            return current_dir\n",
    "        parent_dir = os.path.dirname(current_dir)\n",
    "        if parent_dir == current_dir:\n",
    "            raise FileNotFoundError(f\"{filename} not found in any parent directories.\")\n",
    "        current_dir = parent_dir\n",
    "    # Returns: The path to the project root directory\n",
    "\n",
    "# Find the project root directory\n",
    "root_dir = find_project_root()\n",
    "print(\"Project root directory:\", root_dir)\n",
    "# Returns: The path to the project root directory\n",
    "\n",
    "# Load configuration\n",
    "config_path = os.path.join(root_dir, 'config.json')\n",
    "print(\"Config path:\", config_path)\n",
    "# Returns: The path to the configuration file\n",
    "\n",
    "# Ensure the config file exists\n",
    "if not os.path.exists(config_path):\n",
    "    raise FileNotFoundError(f\"Config file not found at {config_path}\")\n",
    "# Returns: Raises an error if the config file is not found\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "    # Returns: A dictionary `config` containing the configuration settings\n",
    "\n",
    "# Set file paths using the configuration settings\n",
    "processed_data_path = os.path.join(root_dir, config['processed_data_path'])\n",
    "train_path = os.path.join(root_dir, config['train_data_path'])\n",
    "test_path = os.path.join(root_dir, config['test_data_path'])\n",
    "# Returns: Absolute paths for processed data, training data, and testing data\n",
    "\n",
    "# Load the dataset with new features from the specified path\n",
    "df = pd.read_csv(processed_data_path)\n",
    "# Returns: A DataFrame `df` containing the dataset with new features loaded from the processed data path\n",
    "\n",
    "# Verify the columns of the loaded DataFrame\n",
    "print(df.columns)\n",
    "# Returns: Prints the column names of the loaded DataFrame for verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering: Creating New Features\n",
    "\n",
    "In this section, we will create new features for our dataset to enhance its predictive power. The new features will include Charges_Per_Tenure, TotalCharges, Contract_Type, and Payment_Method. These features are derived from existing columns and are designed to provide additional insights for our machine learning models.\n",
    "\n",
    "**Steps**:\n",
    "1. Charges_Per_Tenure: This feature is calculated by dividing MonthlyCharges by the tenure of the customer. It gives an average charge per unit of tenure.\n",
    "2. TotalCharges: This feature is calculated by multiplying MonthlyCharges by the tenure of the customer. It represents the total charges incurred by the customer.\n",
    "3. Contract_Type: This feature is derived from the Contract column, where the contract type (e.g., month-to-month, one year, two years) is mapped to numerical values.\n",
    "4. Payment_Method: This feature is derived from the PaymentMethod column, where different payment methods (e.g., electronic check, mailed check, bank transfer, credit card) are mapped to numerical values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial columns: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female', 'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes', 'InternetService_DSL', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year', 'Churn_No', 'Churn_Yes', 'Charges_Per_Tenure', 'TotalCharges']\n",
      "Added Charges_Per_Tenure and TotalCharges\n",
      "Columns after feature engineering: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female', 'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes', 'InternetService_DSL', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year', 'Churn_No', 'Churn_Yes', 'Charges_Per_Tenure', 'TotalCharges']\n",
      "New features created.\n",
      "Final columns before saving: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'gender_Female', 'gender_Male', 'Dependents_No', 'Dependents_Yes', 'PhoneService_No', 'PhoneService_Yes', 'MultipleLines_No', 'MultipleLines_Yes', 'InternetService_DSL', 'InternetService_Fiber optic', 'Contract_Month-to-month', 'Contract_One year', 'Contract_Two year', 'Churn_No', 'Churn_Yes', 'Charges_Per_Tenure', 'TotalCharges']\n",
      "Dataset with new features saved.\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering with Debugging\n",
    "def create_new_features(df):\n",
    "    \"\"\"\n",
    "    Create new features for the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with new features added.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe to avoid modifying the original one\n",
    "    df = df.copy()\n",
    "\n",
    "    # Initial columns\n",
    "    print(\"Initial columns:\", df.columns.tolist())\n",
    "\n",
    "    # Add Charges_Per_Tenure and TotalCharges if applicable\n",
    "    if 'tenure' in df.columns and 'MonthlyCharges' in df.columns:\n",
    "        df['Charges_Per_Tenure'] = df['MonthlyCharges'] / (df['tenure'] + 1)\n",
    "        df['TotalCharges'] = df['MonthlyCharges'] * df['tenure']\n",
    "        print(\"Added Charges_Per_Tenure and TotalCharges\")\n",
    "\n",
    "    # Mapping for PaymentMethod\n",
    "    payment_mapping = {\n",
    "        'Electronic check': 0,\n",
    "        'Mailed check': 1,\n",
    "        'Bank transfer (automatic)': 2,\n",
    "        'Credit card (automatic)': 3\n",
    "    }\n",
    "    if 'PaymentMethod_Electronic check' in df.columns:\n",
    "        df['Payment_Method'] = df[['PaymentMethod_Electronic check', 'PaymentMethod_Mailed check',\n",
    "                                   'PaymentMethod_Bank transfer (automatic)', 'PaymentMethod_Credit card (automatic)']].idxmax(axis=1)\n",
    "        df['Payment_Method'] = df['Payment_Method'].map(payment_mapping)\n",
    "        print(\"Mapped Payment_Method\")\n",
    "\n",
    "    # Columns after feature engineering\n",
    "    print(\"Columns after feature engineering:\", df.columns.tolist())\n",
    "\n",
    "    print(\"New features created.\")\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df_features = create_new_features(df)\n",
    "\n",
    "# Print final columns before saving\n",
    "print(\"Final columns before saving:\", df_features.columns.tolist())\n",
    "\n",
    "# Save the DataFrame with new features to the specified path\n",
    "processed_data_path = os.path.join(root_dir, config['processed_data_path'])\n",
    "df_features.to_csv(processed_data_path, index=False)\n",
    "print(\"Dataset with new features saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:Splitting the Dataset into Training and Testing Sets\n",
    "\n",
    "In this section, we will split the dataset into training and testing sets to prepare it for model training and evaluation. We will define a function to handle the split and save the resulting datasets to specified paths.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Split Function: We create a function split_data to divide the dataset into training and testing sets based on a specified test size and random seed for reproducibility.\n",
    "2. Split the Data: We use the train_test_split function from scikit-learn to perform the split.\n",
    "3. Save the Splits: The resulting training and testing datasets are saved to the specified file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training (size=5634) and testing (size=1409) sets.\n",
      "Training and testing datasets saved.\n"
     ]
    }
   ],
   "source": [
    "# Identify target variable columns\n",
    "target_column = 'Churn_Yes'\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "def split_data(df, target, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets, stratified by the target variable.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame to be split.\n",
    "    target (str): The target variable column name.\n",
    "    test_size (float): The proportion of the dataset to include in the test split. Default is 0.2 (20% testing, 80% training).\n",
    "    random_state (int): The seed used by the random number generator.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The training and testing DataFrames.\n",
    "    \"\"\"\n",
    "    # Separate the features and the target variable\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split the data into training and testing sets, stratified by the target variable\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    print(f\"Data split into training (size={len(train_df)}) and testing (size={len(test_df)}) sets.\")\n",
    "    # Returns: Two DataFrames - train_df containing the training data and test_df containing the testing data\n",
    "    return train_df, test_df\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = split_data(df_features, target_column)\n",
    "# Save the training and testing datasets to the specified paths\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "print(\"Training and testing datasets saved.\")\n",
    "# Returns: Confirmation message indicating the training and testing datasets have been saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Completed Tasks\n",
    "\n",
    "### Loading the Cleaned Data:\n",
    "\n",
    "1. Imported necessary libraries.\n",
    "2. Loaded the cleaned data from the specified path in the configuration file.\n",
    "\n",
    "### Feature Engineering:\n",
    "\n",
    "1. Created new features to enhance model performance.\n",
    "  - Added Charges_Per_Tenure as the ratio of MonthlyCharges to tenure + 1.\n",
    "  - Calculated TotalCharges as the product of MonthlyCharges and tenure.\n",
    "  - Mapped the Contract column to numerical values.\n",
    "  - Mapped the PaymentMethod column to numerical values.\n",
    "\n",
    "2. Saved the dataset with the new features to the specified path.\n",
    "\n",
    "### Data Splitting:\n",
    "\n",
    "1. Split the dataset with the newly created features into training and testing sets.\n",
    "2. Saved the training and testing datasets to the specified paths.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
